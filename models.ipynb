{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Activation, Dropout, SpatialDropout2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras import backend\n",
    "from keras import layers\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Models:\n",
    "    \n",
    "    \n",
    "    def save_history(self, path, history):\n",
    "        with open(path, 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        model = load_model(path) # Carga el modelo guardado de acuerdo a las perdidas(loss)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def batch_conv_layer(self, feature_size, inputs):\n",
    "        conv1 = Conv2D(feature_size, (3, 3), activation=None, padding='same')(inputs)\n",
    "        BN1 = BatchNormalization()(conv1)\n",
    "        act1 = Activation('relu')(BN1)\n",
    "        \n",
    "        return act1\n",
    "    \n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Se asegura de que el redondeo hacia abajo no baje m√°s del 10%..\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "    \n",
    "    def _depthwise_conv_block(self, inputs, pointwise_conv_filters, alpha, depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "        \"\"\"Adds a depthwise convolution block.\n",
    "        A depthwise convolution block consists of a depthwise conv,\n",
    "        batch normalization, relu6, pointwise convolution,\n",
    "        batch normalization and relu6 activation.\n",
    "        # Arguments\n",
    "            inputs: Input tensor of shape `(rows, cols, channels)`\n",
    "                (with `channels_last` data format) or\n",
    "                (channels, rows, cols) (with `channels_first` data format).\n",
    "            pointwise_conv_filters: Integer, the dimensionality of the output space\n",
    "                (i.e. the number of output filters in the pointwise convolution).\n",
    "            alpha: controls the width of the network.\n",
    "                - If `alpha` < 1.0, proportionally decreases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` > 1.0, proportionally increases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` = 1, default number of filters from the paper\n",
    "                     are used at each layer.\n",
    "            depth_multiplier: The number of depthwise convolution output channels\n",
    "                for each input channel.\n",
    "                The total number of depthwise convolution output\n",
    "                channels will be equal to `filters_in * depth_multiplier`.\n",
    "            strides: An integer or tuple/list of 2 integers,\n",
    "                specifying the strides of the convolution\n",
    "                along the width and height.\n",
    "                Can be a single integer to specify the same value for\n",
    "                all spatial dimensions.\n",
    "                Specifying any stride value != 1 is incompatible with specifying\n",
    "                any `dilation_rate` value != 1.\n",
    "            block_id: Integer, a unique identification designating\n",
    "                the block number.\n",
    "        # Input shape\n",
    "            4D tensor with shape:\n",
    "            `(batch, channels, rows, cols)` if data_format='channels_first'\n",
    "            or 4D tensor with shape:\n",
    "            `(batch, rows, cols, channels)` if data_format='channels_last'.\n",
    "        # Output shape\n",
    "            4D tensor with shape:\n",
    "            `(batch, filters, new_rows, new_cols)`\n",
    "            if data_format='channels_first'\n",
    "            or 4D tensor with shape:\n",
    "            `(batch, new_rows, new_cols, filters)`\n",
    "            if data_format='channels_last'.\n",
    "            `rows` and `cols` values might have changed due to stride.\n",
    "        # Returns\n",
    "            Output tensor of block.\n",
    "        \"\"\"\n",
    "        channel_axis =-1\n",
    "        \n",
    "        in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "        pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "        if strides == (1, 1):\n",
    "            x = inputs\n",
    "        else:\n",
    "            x = layers.ZeroPadding2D(((0, 1), (0, 1)),\n",
    "                                     name='conv_pad_%d' % block_id)(inputs)\n",
    "        x = layers.DepthwiseConv2D((3, 3),\n",
    "                                   padding='same' if strides == (1, 1) else 'valid',\n",
    "                                   depth_multiplier=depth_multiplier,\n",
    "                                   strides=strides,\n",
    "                                   use_bias=False,\n",
    "                                   name='conv_dw_%d' % block_id)(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "        x = layers.ReLU(6., name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "        x = layers.Conv2D(pointwise_conv_filters, (1, 1),\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          strides=(1, 1),\n",
    "                          name='conv_pw_%d' % block_id)(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name='conv_pw_%d_bn' % block_id)(x)\n",
    "        return layers.ReLU(6., name='conv_pw_%d_relu' % block_id)(x)\n",
    "\n",
    "    def _inverted_res_block(self, inputs, expansion, stride, alpha, filters, block_id):\n",
    "        channel_axis =-1\n",
    "\n",
    "        in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "        pointwise_conv_filters = int(filters * alpha)\n",
    "        pointwise_filters = self._make_divisible(pointwise_conv_filters, 8)\n",
    "        x = inputs\n",
    "        prefix = 'block_{}_'.format(block_id)\n",
    "\n",
    "        if block_id:\n",
    "            # Expand\n",
    "            x = layers.Conv2D(expansion * in_channels,\n",
    "                              kernel_size=1,\n",
    "                              padding='same',\n",
    "                              use_bias=False,\n",
    "                              activation=None,\n",
    "                              name=prefix + 'expand')(x)\n",
    "            x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                          epsilon=1e-3,\n",
    "                                          momentum=0.999,\n",
    "                                          name=prefix + 'expand_BN')(x)\n",
    "            x = layers.ReLU(6., name=prefix + 'expand_relu')(x)\n",
    "        else:\n",
    "            prefix = 'expanded_conv_'\n",
    "\n",
    "        # Depthwise\n",
    "        if stride == 2:\n",
    "            x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
    "                                     name=prefix + 'pad')(x)\n",
    "        x = layers.DepthwiseConv2D(kernel_size=3,\n",
    "                                   strides=stride,\n",
    "                                   activation=None,\n",
    "                                   use_bias=False,\n",
    "                                   padding='same' if stride == 1 else 'valid',\n",
    "                                   name=prefix + 'depthwise')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      epsilon=1e-3,\n",
    "                                      momentum=0.999,\n",
    "                                      name=prefix + 'depthwise_BN')(x)\n",
    "\n",
    "        x = layers.ReLU(6., name=prefix + 'depthwise_relu')(x)\n",
    "\n",
    "        # Project\n",
    "        x = layers.Conv2D(pointwise_filters,\n",
    "                          kernel_size=1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          activation=None,\n",
    "                          name=prefix + 'project')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      epsilon=1e-3,\n",
    "                                      momentum=0.999,\n",
    "                                      name=prefix + 'project_BN')(x)\n",
    "\n",
    "        if in_channels == pointwise_filters and stride == 1:\n",
    "            return layers.Add(name=prefix + 'add')([inputs, x])\n",
    "        return x\n",
    "    \n",
    "    def get_unet_model_1(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "        #conv10 = Conv2D(classes, (1, 1), padding=\"valid\")(conv9)\n",
    "        #reshape1 = Reshape((input_shape[0]*input_shape[1], classes))(conv10)\n",
    "        #x = Activation(\"softmax\")(reshape1)\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_2(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        \n",
    "        conv2 = self.batch_conv_layer(64, pool1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        \n",
    "        conv3 = self.batch_conv_layer(128, pool2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        \n",
    "        conv4 = self.batch_conv_layer(256, pool3)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = self.batch_conv_layer(128, up7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self.batch_conv_layer(64, up8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_3(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_4(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        conv1 = self.batch_conv_layer(32, conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = self.batch_conv_layer(64, pool1)\n",
    "        conv2 = self.batch_conv_layer(64, conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = self.batch_conv_layer(128, pool2)\n",
    "        conv3 = self.batch_conv_layer(128, conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = self.batch_conv_layer(256, pool3)\n",
    "        conv4 = self.batch_conv_layer(256, conv4)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = self.batch_conv_layer(128, up7)\n",
    "        conv7 = self.batch_conv_layer(128, conv7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self.batch_conv_layer(64, up8)\n",
    "        conv8 = self.batch_conv_layer(64, conv8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "        conv9 = self.batch_conv_layer(32, conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_5(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "        conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "        conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "        up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "        conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "        conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_6(self, input_shape, classes, loss, metrics):\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        conv1 = self.batch_conv_layer(32, conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = self.batch_conv_layer(64, pool1)\n",
    "        conv2 = self.batch_conv_layer(64, conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = self.batch_conv_layer(128, pool2)\n",
    "        conv3 = self.batch_conv_layer(128, conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = self.batch_conv_layer(256, pool3)\n",
    "        conv4 = self.batch_conv_layer(256, conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        \n",
    "        conv5 = self.batch_conv_layer(512, pool4)\n",
    "        conv5 = self.batch_conv_layer(512, conv5)\n",
    "        \n",
    "        up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "        conv6 = self.batch_conv_layer(256, up6)\n",
    "        conv6 = self.batch_conv_layer(256, conv6)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "        conv7 = self.batch_conv_layer(128, up7)\n",
    "        conv7 = self.batch_conv_layer(128, conv7)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self.batch_conv_layer(64, up8)\n",
    "        conv8 = self.batch_conv_layer(64, conv8)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "        conv9 = self.batch_conv_layer(32, conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_7(self, input_shape, classes, loss, metrics):\n",
    "        #Mobile net v2 medium\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        conv1 = self.batch_conv_layer(32, conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = self._inverted_res_block(pool1, filters=64, alpha=1.0, stride=1,expansion=6, block_id=1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = self._inverted_res_block(pool2, filters=128, alpha=1.0, stride=1,expansion=6, block_id=3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = self._inverted_res_block(pool3, filters=256, alpha=1.0, stride=1,expansion=6, block_id=5)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = self._inverted_res_block(up7, filters=128, alpha=1.0, stride=1,expansion=6, block_id=11)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self._inverted_res_block(up8, filters=64, alpha=1.0, stride=1,expansion=6, block_id=13)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "        conv9 = self.batch_conv_layer(32, conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_8(self, input_shape, classes, loss, metrics):\n",
    "        #Mobile net v2 large\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        conv1 = self.batch_conv_layer(32, conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = self._inverted_res_block(pool1, filters=64, alpha=1.0, stride=1,expansion=6, block_id=1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = self._inverted_res_block(pool2, filters=128, alpha=1.0, stride=1,expansion=6, block_id=3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = self._inverted_res_block(pool3, filters=256, alpha=1.0, stride=1,expansion=6, block_id=5)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        \n",
    "        conv5 = self._inverted_res_block(pool4, filters=512, alpha=1.0, stride=1,expansion=6, block_id=7)\n",
    "        \n",
    "        up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "        conv6 = self._inverted_res_block(up6, filters=256, alpha=1.0, stride=1,expansion=6, block_id=9)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "        conv7 = self._inverted_res_block(up7, filters=128, alpha=1.0, stride=1,expansion=6, block_id=11)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self._inverted_res_block(up8, filters=64, alpha=1.0, stride=1,expansion=6, block_id=13)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "        conv9 = self.batch_conv_layer(32, conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_9(self, input_shape, classes, loss, metrics):\n",
    "        # Mobile net v1 small\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        \n",
    "        conv2 = self._depthwise_conv_block(pool1, 64, alpha=1.0, depth_multiplier=1, block_id=1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        \n",
    "        conv3 = self._depthwise_conv_block(pool2, 128, alpha=1.0, depth_multiplier=1, block_id=2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        \n",
    "        conv4 = self._depthwise_conv_block(pool3, 256, alpha=1.0, depth_multiplier=1, block_id=3)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = self._depthwise_conv_block(up7, 128, alpha=1.0, depth_multiplier=1, block_id=4)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self._depthwise_conv_block(up8, 64, alpha=1.0, depth_multiplier=1, block_id=5)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model\n",
    "    \n",
    "    def get_unet_model_10(self, input_shape, classes, loss, metrics):\n",
    "        # Mobile net v1 medium\n",
    "        inputs = Input(shape=input_shape)#, dtype=tf.float16)\n",
    "        conv1 = self.batch_conv_layer(32, inputs)\n",
    "        conv1 = self.batch_conv_layer(32, conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = self._depthwise_conv_block(pool1, 64, alpha=1.0, depth_multiplier=1, block_id=1)\n",
    "        conv2 = self._depthwise_conv_block(conv2, 64, alpha=1.0, depth_multiplier=1, block_id=2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = self._depthwise_conv_block(pool2, 128, alpha=1.0, depth_multiplier=1, block_id=3)\n",
    "        conv3 = self._depthwise_conv_block(conv3, 128, alpha=1.0, depth_multiplier=1, block_id=4)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = self._depthwise_conv_block(pool3, 256, alpha=1.0, depth_multiplier=1, block_id=5)\n",
    "        conv4 = self._depthwise_conv_block(conv4, 256, alpha=1.0, depth_multiplier=1, block_id=6)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "        conv7 = self._depthwise_conv_block(up7, 128, alpha=1.0, depth_multiplier=1, block_id=7)\n",
    "        conv7 = self._depthwise_conv_block(conv7, 128, alpha=1.0, depth_multiplier=1, block_id=8)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "        conv8 = self._depthwise_conv_block(up8, 64, alpha=1.0, depth_multiplier=1, block_id=9)\n",
    "        conv8 = self._depthwise_conv_block(conv8, 64, alpha=1.0, depth_multiplier=1, block_id=10)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "        conv9 = self.batch_conv_layer(32, up9)\n",
    "        conv9 = self.batch_conv_layer(32, conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  #sigmoid\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "        config = model.get_config()\n",
    "        new_model= model.from_config(config)\n",
    "        \n",
    "        new_model.compile(optimizer=Adam(lr=1e-5), loss=loss, metrics=metrics)\n",
    "\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
